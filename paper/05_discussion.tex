\chapter{Discussion}
\label{cha:discussion}

In this chapter I will discuss the diverse results of the experiment, analyzing the learners' 
interaction with the developed technology and my opinion on their experience and how I interpret 
the changes, if any. I'll try to summarize my ideas and answer each of the research questions mentioned
in \nameref{cha:introduction} chapter, subsequently analyzing the chosen evaluation methodology, and
how the results could have been foreseen, or in others words, if anything new could be learned from the procedure.


Taking into consideration the main goal of the application, namely to create an effective eLearning tool
to help students learn using an innovative smart speaker application also functional for informal 
activities such as multitasking, then the results show that yes, the users' reception of the technology was
very positive and it serves its purpose. If on the other hand we define the goal as a more complex learning 
tool, that actively creates a community of practice, that functions as an informal learning tool, that 
transfers tacit knowledge to a more explicit and codifiable form through repetition and simplicity, a tool
that conveys micro content effectively, then the analysis can start becoming more vague and blurry, for
these facts were not so vastly assessed with the experiment, and could only be observed in a much larger 
time scale firstly and with many more users and experiments secondly. 
If lastly the goal of the experiment was 
purely to assess the research questions and to try to understand users' learning processes using eLearning
tools in comparison to traditional ones and more orthodox methodologies, then the results were even less
certain, for these conclusions can not be so easily drawn from such a brief experiment.

With that being said, one can still hypothesize taking the results into consideration for more vast and 
general points, such as the complex learning tool and difference in the learning processes as above 
mentioned.

I will start by interpreting how these results could answer the research questions and followed by 
why they implement all the more abstract features as presented in the \nameref{cha:introduction}.

\section{Research Questions}
Referring back to the presented research questions exposed in the \nameref{cha:introduction} chapter:

\begin{enumerate}
	
\item What is the learners attitude towards less traditional learning tools, that:
    \begin{enumerate}
        \item \label{question:1.1} 
            take advantage of more informal practices?
        \item \label{question:1.2}
            use innovative technologies?
        \item \label{question:1.3}
            try to combine social, informal and micro learning in one place?
    \end{enumerate}

\item \label{question:2} 
    Are users aware of how important/efficient this less traditional ways of learning are?
\item \label{question:3} 
    Are users aware of how important/efficient use of technology to help the learning process is?

\end{enumerate}

\textbf{\ref{question:1.1}:} As observed in the experiment, the attitude towards practices that take
advantage of more informal practices depends from learner to learner. Their attitude towards informal 
practices can take three shapes. One, they are unaware of the importance and unopened to change, two, they
are unaware of the importance but opened to change and three, they are aware of the importance and already 
have a positive attitude. The ones with the unopened attitude remained so, even if the experience was 
enjoyable, and the other two types remained pleased and positive. So according to this experiment, learners
can have these three stand points and their opinion is unlikely to switch polarity.

\textbf{\ref{question:1.2}:} These question has a similar answer as the previous one, though in this case
another factor comes into play, namely the fear that such technologies will be difficult to learn from 
some parties. This fear of learning just adds complexity to the already hard learning process in the first 
place, so even though it might prove easier for the given task in the future, it serves as a strong 
unmotivation.

\textbf{\ref{question:1.3}:} Regarding this question all participants had a positive mindset, for they were
all aware of how important social circles are to learning, and a tool that combines that with other learning
styles can only present positive outcomes.

\textbf{\ref{question:2}:} Most users were not aware of the importance of such learning ways. Even though
most of them already used such methodologies, in some cases completely unaware of the fact, they mostly 
considered it a lack of understanding of the more traditional learning habits, in a form
of inferiority almost, completely neglecting the possibility that such ways of learning could be as 
important.

\textbf{\ref{question:3}:} Here the participants of the also differ. Every single one of the participants 
agree and admitted the importance of technology as something ubiquitous and advantageous in almost every 
field. But regarding learning habits, the answer was not so obvious anymore and needless to say, didn't 
change after use of the developed tool.


\section{Complex Learning Tool}


Reexamining the tool's second goal, to become a complex eLearning application, to cover the four goals
and ideas expressed in the \nameref{cha:introduction} and \nameref{cha:relatedwork} sections, my opinion
regarding each of the topics is the following:

\begin{itemize}
    \item \textbf{Communities of Practice: } the ability to engage in communities of practice, forming 
        bonds on common interests and sharing knowledge is not fully covered by the application and 
        not completely understood by its users. The fact that the users use the platform associated 
        with an online account, is still not enough to consider it a CoP platform, for all the necessary
        conditions are missing. The main architecture was layed out to further improve this aspect in
        the future, where only small steps are needed to implement the right conditions. The next steps
        would be to create user profiles, where one could follow and display which topics he/she is 
        currently studying or interested in. Another thing would be to leave comments and flags, so 
        learners leave suggestions on how to change or improve some questions or content. Rating questions
        would also be important to allow the interaction and build hierarchical systems between the users.
    \item \textbf{Informal Learning: } this next topic is the most widely covered learning paradigm 
        of the entire application. The fact that its an extracurricular form of learning is already
        in itself a form of informal learning, but the application also makes use of a smart speaker, 
        which allows the student to interact and learn whilst performing different daily tasks. 
    \item \textbf{Tacit Knowledge: } this aspect can not be easily assessed. The transformation of
        tacit into explicit knowledge is a very vague and abstract concept. But the fact that using this
        application one can practice any topic, also topics that are better learned with tacit 
        knowledge techniques, and that it codes the knowledge into a written form hints that this 
        characteristic too is achieved by the tool.
    \item \textbf{Micro-Learning: } this concept is also very accurately covered by the application. 
        it certainly compels its users to invest small but regular intervals of time, for it can be matched
        with any hand activity that doesn't protrude the students' concentration, making it optimal for
        the conveyance of small portions of micro content at a regular pace. According to the experiment
        as well, this was one of the most complimented features. 
\end{itemize}



\section{Analysis of Evaluation}

Looking back at the procedure, I think the methodology chosen was appropriate, for the fact that it takes
in consideration mostly the users' reviews of the tool and tries to gather suggestions on all missing 
features and potential future improvements. The size of the experiment was in my opinion small. It should
have been much larger both in terms of time as for the participants. I think the experiment should take
place repeatedly during a time span of maybe one semester, following the learning habits and interaction
with the application across different learning episodes. That would potentially change the opinion of the
participants with experience, as opposed to fast impressions. These was unfortunately unfeasible, for the
development of the application, which was the main part of the thesis already took half of a semester of
effort and the logistical difficulties caused by the global pandemic crisis were unforeseen. 

The expected results beforehand changed from before the application was written, to after, as well as 
before the related work and concepts were understood to after, but in general the results were expected.
It was expected that people with more eagerness would keep the same mentality, despite the effectiveness
and utility of the tool, and the ones less eager would also remain unchanged. 

One can learn that the attitude and behaviour towards technology is more important than the experience 
itself. If one wishes to implement efficient tools in a learning system the attitude towards technology 
of the people in power needs to be clear. That is the number one factor in psychology and the power of 
the tool itself comes in second place.

For the future I would wish to enhance the written tool with all remaining features, as well as the
suggested ones and attempt once again the experiment, this time observing the learners across a longer
time span. 

